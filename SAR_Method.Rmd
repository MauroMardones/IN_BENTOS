---
title: "Methodological implementation of Swept Area Ratio (SAR) in the wedge clam fishery Chamelea galllina in the Gulf of Cádiz, Spain"
subtitle: "Proyecto IN-BENTO (Desarrollo de bioindicadores para el seguimiento de los ecosistemas intermareal y submareal sometidos a explotación marisquera en el litoral de Huelva) (Consejería de Universidad, Investigación e Innovación de la Junta de Andalucía y el Gobierno de España. Financiado por la Unión Europea-NextGeneration EU. MRR)"
author: "Magro, A., Mardones. M., Rodríguez-Rua, A., Román. S. and Delgado, M"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: INBENTO.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
output:
  html_document:
    keep_md: true
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: cosmo
    fontsize: 0.9em
    linestretch: 1.7
    html-math-method: katex
    self-contained: true
    code-tools: true
---

\newpage

```{r setup1, echo =FALSE}
rm(list = ls())
knitr::opts_chunk$set(message = FALSE,
                      eval = TRUE,
                      warning = FALSE,
                      echo=TRUE,
                      fig.align = 'center',
                      dev = 'jpeg',
                      dpi = 300, 
                      fig.align='center')
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```

```{r libs, message=FALSE}
library(tidyverse)
library(ggridges)
library(readxl)
library(here)
library(lubridate)
library(readr)
library(ggthemes)
library(hrbrthemes)
library(kableExtra)
library(gtsummary)
library(egg)
library(ggthemes)
library(geosphere)
library(sp)
library(sf)
```

# ABSTRACT

This abstract presents a method to calculate the SAR (Swept Area Ratio) using satellite data from a fleet of nearly 100 vessels in the artisanal fishing of Chirla in the Gulf of Cadiz. Artisanal fisheries, like Chirla fishing, often lack comprehensive data, hampering effective management. Leveraging satellite imagery, particularly through green boxes technology, offers a unique advantage by providing real-time spatial information on fishing activity. With this method, we can continuously identify the fleet's effort in both spatial and temporal terms. The objective is to develop an ad hoc approach reproducible through accessible codes and open data, facilitating sustainable fisheries management in the Gulf of Cadiz and beyond.

# INTRODUCTION


Making better use of tracking data can reveal the spatiotemporal and intraspecific variability of species distributions 

# METHODOLOGY

## DATA SATELITAL VESSEL

Por ahora solo trabajaremos con la data entregada por Candelaria Burgos para Chirla, que son los datos del año 2008 y 2009.

```{r}
cajas2009 <- c("Draga_01_2009.txt",
           "Draga_02_2009.txt",
           "Draga_03_2009.txt", 
           "Draga_04_2009.txt" ,
           "Draga_05_2008.txt" ,
           "Draga_06_2008.txt",
           "Draga_07_2008.txt" ,
           "Draga_08_2008.txt",
           "Draga_09_2008.txt" ,
           "Draga_10_2008.txt",
           "Draga_11_2008.txt" ,
           "Draga_12_2008.txt")
# caja1 <- read.table(here("DATOS",
#                          "Cajas verdes chirla",
#                          "Draga_2008_2009",
#                          "Draga_01_2009.txt"), 
#                      sep = ";",
#                     header = TRUE)

# Lista para almacenar los datos
lista_datos <- list()
# Ciclo for para leer cada archivo
for (archivo in cajas2009) {
  # Ruta completa del archivo
  ruta <- here("DATOS", 
               "Cajas verdes chirla",
               "Draga_2008_2009", archivo)
  # Leer el archivo y agregarlo a la lista
  datos <- read.table(ruta, sep = ";", header = TRUE)
  lista_datos[[archivo]] <- datos
}
```


```{r}
#Uno y verifico dimension
cajas2009uni <- do.call(rbind, 
                        lista_datos)
```

## RESULTS 

Identify the data base structure

```{r}
glimpse(cajas2009uni)
```




```{r}
#cambio el formato de fechas:
cajas2009uni$FECHA <- dmy(cajas2009uni$FECHA) 

cajassep <- cajas2009uni %>%
  mutate(ANO = year(FECHA),
         MES = month(FECHA),
         DIA = day(FECHA))
```

De forma simple compruenbo los meses y dias con actividad de los datos sin filtrar;


```{r eval=FALSE}

diahis <- ggplot()+
  geom_histogram(aes(cajassep$DIA), 
                     col=2,
                     fill="white",
                 binwidth = 1)+
  theme_few()
meshis <- ggplot()+
  geom_histogram(aes(cajassep$MES), 
                     col=3,
                     fill="white",
                 binwidth = 1)+
  theme_few()
velhis <- ggplot()+
  geom_histogram(aes(cajassep$N_VELOCIDAD), 
                     col=4,
                     fill="white",
                 binwidth = 0.1)+
  theme_few()
ggarrange(diahis, meshis, velhis, ncol=3)
```

Los métodos para la estimación y cartografiado del esfuerzo pesquero a partir de los datos de los VMS ya se han estudiado en varias pesquerías anteriormente. Estos estudios recomiendan un proceso en varios pasos según [@Cojan2012]: 

1- Borrar los registros duplicados, 

```{r}
# Encontrar filas duplicadas
filas_duplicadas <- duplicated(cajassep)
# Mostrar las filas duplicadas
datos_duplicados <- cajassep[filas_duplicadas, ]

# Opcionalmente, para eliminar filas duplicadas manteniendo solo la última ocurrencia de cada fila duplicada:
cajasfil <- cajassep[!duplicated(cajassep, 
                                 fromLast = TRUE), ]
```

2- Borrar los registros en puertos. 

```{r}
cajasfilp <- cajasfil %>% 
  filter(N_EN_PUERTO == 0)
```


```{r}
velhis <- ggplot()+
  geom_histogram(aes(cajasfilp$N_VELOCIDAD,
                     fill=cajasfilp$N_VELOCIDAD < 1.5),
                 binwidth = 0.02)+
  scale_fill_viridis_d()+
  theme_few()+
  theme(legend.position = "none")
velhis
```

3- Calcular el intervalo de tiempo entre registros sucesivos, 

La idea es identificar los registros con tiempo efectivo de arrastre como lo muestra la Figura \ref{fig:esq};

```{r esq, echo=TRUE, out.width = "50%", fig.align='center', fig.cap="\\label{esq}Umbrarl de definiciones para calculo de velocidad de arrantre"}
knitr::include_graphics("FIG/umbralveloc.png")
```
De esta forma, a cada señal proporcionada por la caja verde se le asignó una actividad: pesca, maniobra o navegada. En la figura 8 se puede ver un histograma que representa el número de registros en función de la velocidad para los registros filtrados, en él se observa cómo han desaparecido los registros en puerto y que existen tres modas correspondientes a las actividades mencionadas, maniobras (M), pesca (P) y navegaciones (N). [@Cohan2012]

Los registros en los cuales la velocidad del buque fue inferior a 1.5 nudos o entre 3.5 y 6 nudos, fueron considerados como maniobras de pesca (actividad "M"), tales como la virada y largada del arte o el reposicionamiento del buque precedente al arrastre.

```{r}
head(cajasfil)

cajasfil2 <- cajasfil %>%
  mutate(MANIOBRA = case_when(
    N_VELOCIDAD >= 0 & N_VELOCIDAD < 1.5 ~ "M",
    N_VELOCIDAD >= 1.5 & N_VELOCIDAD < 3.5 ~ "P",
    N_VELOCIDAD >= 3.5 & N_VELOCIDAD < 6 ~ "M",
    N_VELOCIDAD >= 6 & N_VELOCIDAD <= 10 ~ "N",
    TRUE ~ NA_character_  # Por si acaso hay valores fuera de los rangos especificados
  ))

dim(cajasfil2)

```



4- Ahora calculo las distancias entre puntos. como??

\newpage
### Método 1

```{r echo=TRUE}
calcular_DISTANCIA <- function(lat1, lon1, lat2, lon2) {
  # Converto to radians
  lat1_rad <- lat1 * pi / 180
  lon1_rad <- lon1 * pi / 180
  lat2_rad <- lat2 * pi / 180
  lon2_rad <- lon2 * pi / 180
  # Ratio earth in mts
  radio_tierra <- 6371000
  # Calculate distance using haversine equation
  dlat <- lat2_rad - lat1_rad
  dlon <- lon2_rad - lon1_rad
  a <- sin(dlat / 2)^2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2)^2
  c <- 2 * atan2(sqrt(a), sqrt(1 - a))
  DISTANCIA <- radio_tierra * c
  return(DISTANCIA)
}

datos <- cajasfil2
# Convertir la columna de fecha y hora a un objeto POSIXct con lubridate
datos$fecha_hora <- ymd_hms(paste(datos$FECHA, datos$HORA))

# Ordenar el dataframe por fecha y hora
datos <- datos %>% 
  arrange(fecha_hora)
# Calcular la DISTANCIA para cada fila del dataframe
datos$DISTANCIA <- mapply(calcular_DISTANCIA,
                          datos$N_LATITUD,
                          datos$N_LONGITUD,
                          lag(datos$N_LATITUD),
                          lag(datos$N_LONGITUD))

# La primera fila tendrá NA ya que no hay punto anterior
datos$DISTANCIA[1] <- NA
head(datos)
```

### Método 2

Probar forma que indica Ana Magro, que es calcular tiempo de arrastre X Velocidad. La idea es calcular el tiempo entre registros dado por `fecha_hora`. Y multiplicamos por `N_VELOCIDAD`

```{r}
datosp <- datos %>% 
  arrange(fecha_hora) %>% 
 mutate(diff = fecha_hora - lag(fecha_hora),
         diff_secs = as.numeric(diff, units = 'secs'))
```



5- Diferenciar entre registros de pesca y no pesca basándose en la velocidad y solo dejó los registros `P`

```{r}
datos1 <- datosp %>% 
  filter(MANIOBRA=="P")
```

ahora dejo valores de distancia menores a 1 km (preguntar). Luego calculo las variables de velocidad en metros/seg. y tiempo recorrido por la rastra. 

```{r}
datosfil <- datos1 %>% 
  filter(DISTANCIA < 5000) %>% 
  mutate(VELONUE = N_VELOCIDAD*0.51444, # de nudos a mts/seg
        DISTANCIA2 = diff_secs * VELONUE, # por ahora no ocuparé el Metodo 2
        SA = DISTANCIA*2.5) # cDato de anchura draga chirla MD y LS
        
```

Gafico velocidad y SA promedio por barco

```{r}
plotvel <- ggplot(datosfil %>% 
               group_by(MATRICULA))+
  geom_boxplot(aes(x = reorder(MATRICULA, VELONUE),
                   y = VELONUE),
               outliers = FALSE)+
  theme_few()+
  theme(axis.text.x = element_text(angle = 90,
                                     hjust = 1,
                                     vjust = 0.5,
                                     size = 5))+
  xlab("Matriculas") +
  ylab(expression(paste(Velocidad (m/s))))
  
  #facet_wrap(.~MES)

plotdi <- ggplot(datosfil %>% 
               group_by(MATRICULA))+
  geom_boxplot(aes(x = reorder(MATRICULA, DISTANCIA), 
                   y = DISTANCIA),
               outliers = FALSE)+
  theme_few()+
  theme(axis.text.x = element_text(angle = 90,
                                     hjust = 1,
                                     vjust = 0.5,
                                     size = 5))+
  xlab("Matriculas") +
  ylab(expression(paste(Distancia (m))))

ggarrange(plotvel, plotdi, 
          ncol =1)
```
Calculo el SAR

De acuerdo a @Church2016, el cálculo de la Razón del Área Barrida (Swept Area Ratio, SAR) `SA` es el área barrida (mts/2), `CA` es el área de la celda y `SAR` es la proporción del área barrida (equivalente al número de veces que la celda fue barrida).

donde;

$$
SAr = \frac{SA}{CA}
$$

donde `SA`sera la distancia recorrida el arrastre y la apertura en metros del draga, es decir;

$$
SA = Distancia \times Apertura \ Draga
$$
Pero primero, debemos engrillar la data y luego calcular por cada celda


Ahora produzco un mapa de las grillas utilizadas en la pesquería de Chirla. Estos datos vectoriales fueron obtenidos desde la paina oficial de datos espaciales de la Junta de Andalucia [Shapesfile](https://portalrediam.cica.es/descargas?path=%2F08_AMBITOS_INTERES_AMBIENTAL%2F02_LITORAL_MARINO%2F04_SOCIOECONOMIA%2FZonasProduccionMoluscos)

## Leo Shapes y transformo a la proyección correcta.
```{r echo=TRUE, message=FALSE, warning=FALSE}
costandalucia <- st_read(here("SHP_Chirla",
                              "costa_proyectada.shp"))
grilla <- st_read(here("SHP_Chirla",
                              "cuadriculas_definitivo.shp"))
bati <- st_read(here("SHP_Chirla",
                     "batimetria_rediam20x20_10m_id.shp"))
habitat <- st_read(here("SHP_Chirla",
                     "Habitats_region_IV.shp"))
demarca <- st_read("SHP_Chirla",
                   "Demarcaciones_Marinas_WGS84_2018")

# Transformo a objetos sf con la crs correcta
grilla1 <- st_transform(grilla, 
                        "+init=epsg:4326")
costandalucia1 <- st_transform(costandalucia,
                               "+init=epsg:4326")
bati1 <- st_transform(bati,
                      "+init=epsg:4326")

habi1 <- st_transform(habitat,
                      "+init=epsg:4326")

dema1 <- st_transform(demarca,
                      "+init=epsg:4326")

```


Mapa test
```{r}
# Crea un mapa de Europa
europe_map <- map_data("world")

# Visualiza el mapa de Europa
ggplot() +
  geom_polygon(data = europe_map, 
               aes(x = long, 
                   y = lat, 
                   group = group), 
               fill = "#fee8c8", 
               color = "black") +
  coord_fixed(1.3) +  # Ajusta la relación de aspecto
  theme_few()  # Estilo del gráfico

```


Ahora identifico la base que quiero plotear y hago el calculo de `SAR`

```{r ssmu1}
sabd <- datosfil %>% 
  st_as_sf(coords = c("N_LONGITUD", "N_LATITUD"),  
                  crs = "+init=epsg:4326") %>% 
  mutate(CELDAM2 = rep(857476),
         length.out = nrow(datosfil),
         SAR= (SA/CELDAM2)*100)
```

This grid has the same characteristics as the environmental data grids
that will be called up later. This grid is 1x0.5 degrees which allows a
clear visualization of the processes, whether biological and/or
environmental.

```{r gri}
# the first object dsargrillada# the first object drives the output geometry
grilla2 <- grilla1 %>%
  rename("Estaciones" = "ID_CELDA") 
# ahora genero la base sf para el sar
grillasar <- st_join(grilla2, sabd)
```


Y ahora veo como es el ttotal del SAR en % por celda

```{r}
grillasardf <- as.data.frame(grillasar)
sarest <- grillasardf %>% 
  group_by(Estaciones) %>% 
  summarize(TOTALSAR = mean(SAR))
```
ploteo SAR

```{r warning=FALSE}
masrend <- ggplot() +
  #geom_sf(data = lito1, fill="white", color="blue") +
  geom_sf(data = grilla2, 
          fill=NA, 
          color="red") +
  geom_sf(data = costandalucia1, 
          fill="#fee8c8") +
  geom_sf(data = grillasar %>% 
            filter(SAR>0,
                   SAR<1) %>% 
            drop_na(SAR), 
          aes(fill=cut(SAR,
                       breaks = seq(0, 1, by = 0.2))))+
  # geom_sf(data = fisicomar1, alpha=0.1,
  #         linetype=5) +
  scale_fill_brewer(type = "qual",
                    #labels = label, # if you must
                    palette = "Reds",
                    name = "SAR") +
    coord_sf() +
  xlab(expression(paste(Longitude^o,~'O'))) +
  ylab(expression(paste(Latitude^o,~'S')))+
  # ggrepel::geom_label_repel(
  #   data = zonapro1,
  #   aes(label = ZONA, geometry = geometry),
  #   stat = "sf_coordinates",
  #   min.segment.length = ,
  #   colour = "black",
  #   size = 2,
  #   segment.colour = "black",
  #   box.padding = 0.7,
  #   max.overlaps = 50) +
  theme_few()+
  xlim(-7.6,-6.3)+
  ylim(36.65, 37.3)
masrend
```


## Calculo de lances por estacion o por habitat 

Pero para esto, primer debemos asignar un ID para cada operación.

```{r}
# Primero, ordena los datos por matrícula y fecha
idlance <- grillasar %>%
  arrange(MATRICULA, FECHA, HORA)

# Luego, calcula la diferencia en segundos entre cada registro y el siguiente
idlance2 <- idlance %>%
  mutate(diff_secs_next = lead(diff_secs, default = 0))

# Ahora, crea una nueva columna que sea TRUE si la diferencia en segundos es mayor a 1200 (20 minutos)
# o si es el último registro de la misma matrícula y fecha
idlance3 <- idlance2 %>%
  mutate(ID_Lance = ifelse(diff_secs_next > 1200 | 
                             lead(MATRICULA) != MATRICULA | 
                             lead(FECHA) != FECHA, TRUE, FALSE))
# Convierte la columna ID_Lance a formato numérico y luego asigna un ID incremental
idlance4 <- idlance3 %>%
  group_by(MATRICULA) %>% 
  mutate(ID_Lance = cumsum(ID_Lance))

# Muestra los primeros registros para verificar
head(idlance4)
```

Solo para visualizar, cambio el objeto a `data.frame`. Pero debo considerar `idlance4` para engrillar.

```{r}
idlance5 <- as.data.frame(idlance4)

sumest <- idlance5 %>% 
  group_by(Estaciones,MATRICULA) %>% 
  summarise(num_lances = n_distinct(ID_Lance, na.rm = TRUE))
```



\newpage

# REFERENCIAS
